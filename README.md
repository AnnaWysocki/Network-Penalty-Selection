# Network-Penalty-Selection
Simulation comparing four methods for selecting the penalty parameter in the graphical lasso. We do two simulations. The first uses a psychological dataset to creat the population covariance matrix (Code for this simulation can be found in PTSDSim). The second simulation uses the R package BDGraph to create the population covariance matrix (Code for this simulation can be found in BDgraphSim).  

Abstract: Network models are gaining popularity as a way to estimate direct effects among psychological   variables and investigate the structure of constructs. A key feature of network estimation is determining which edges are likely to be non-zero. In psychology, this is commonly achieved through the graphical lasso regularization method that estimates a precision matrix of Gaussian variables using an L1-penalty to push small values to zero. A tuning parameter, lambda, controls the sparsity of the network. There are many methods to select lambda, which can lead to vastly different graphs. The most common approach in psychological network applications is to minimize the extended Bayesian Information Criterion, but the consistency of this method for model selection has primarily been examined in high dimensional settings that are uncommon in psychology. Further,  there is some evidence that alternative selection methods may have superior performance. Here, with simulation, we compare four different methods for selecting lambda, including the stability approach to regularization selection (StARS), K-fold cross-validation, the rotation information criterion (RIC), and the extended Bayesian information criterion (EBIC). Our results demonstrate that penalty parameter selection should be made based on data characteristics and the inferential goal (e.g., increase sensitivity versus avoidance of false positives). We end with recommendations for selecting the penalty parameter when using the graphical lasso.
